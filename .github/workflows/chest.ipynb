{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM615aTklPY9",
        "outputId": "54e6ffb0-58ca-4a97-ff76-240e92d2aed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrQLIFGDohDa",
        "outputId": "49966ede-0d28-4978-dedc-cd9616385a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 532, 399, 8)       208       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 264, 198, 8)       1608      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 264, 198, 8)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 130, 97, 8)        1608      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 42, 31, 16)        6288      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 21, 15, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 4, 32)          41504     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 3, 2, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                6176      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,458\n",
            "Trainable params: 57,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/4\n",
            "20/20 [==============================] - 34s 1s/step - loss: 0.6677 - accuracy: 0.6218\n",
            "Epoch 2/4\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.6225 - accuracy: 0.7147\n",
            "Epoch 3/4\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6645 - accuracy: 0.6587\n",
            "Epoch 4/4\n",
            "20/20 [==============================] - 19s 970ms/step - loss: 0.6632 - accuracy: 0.6250\n",
            "Found 5239 images belonging to 2 classes.\n",
            "164/164 [==============================] - 185s 1s/step - loss: 0.6028 - accuracy: 0.7412\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6028227210044861, 0.7411719560623169]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "\n",
        "data = keras.preprocessing.image.ImageDataGenerator(\n",
        "preprocessing_function=lambda x:x/255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/test\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "# Initialize empty lists to store the images and labels\n",
        "# images = []\n",
        "# labels = []\n",
        "\n",
        "# # Iterate over the batches in the data generator\n",
        "# for batch in data:\n",
        "#     batch_images, batch_labels = batch\n",
        "    \n",
        "#     # Add the batch images and labels to the respective lists\n",
        "#     images.extend(batch_images)\n",
        "#     labels.extend(batch_labels)\n",
        "    \n",
        "#     # Break the loop when all batches have been processed\n",
        "#     if len(images) >= len(data.filenames):\n",
        "#         break\n",
        "\n",
        "# # Convert the lists to numpy arrays\n",
        "# images = np.array(images)\n",
        "# labels = np.array(labels)\n",
        "\n",
        "# for d in data:\n",
        "#   images.append(d[0])\n",
        "#   labels.append(d[1])\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input((1600,1200,1)),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(2,2), activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(2,2), activation='relu'),\n",
        "    keras.layers.Conv2D(16,(7,7),strides=(3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Conv2D(32,(9,9),strides=(2,2), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32,activation=\"relu\"),\n",
        "    keras.layers.Dense(2,activation=\"softmax\"),\n",
        "    \n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01,nesterov=True,momentum=0.9),loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "             metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(data,verbose=1,epochs=4)\n",
        "\n",
        "data_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "preprocessing_function=lambda x:x/255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/train\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "model.evaluate(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNLDu-NElZ1d",
        "outputId": "13b33bf2-20df-457f-88cd-ce53733c8e39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 532, 399, 8)       208       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 264, 198, 8)       1608      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 264, 198, 8)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 130, 97, 8)        1608      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 42, 31, 16)        6288      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 21, 15, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 4, 32)          41504     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 3, 2, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                6176      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,458\n",
            "Trainable params: 57,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 32s 964ms/step - loss: 0.6820 - accuracy: 0.5994\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 20s 974ms/step - loss: 0.6580 - accuracy: 0.6250\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 20s 992ms/step - loss: 0.6475 - accuracy: 0.6394\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.5684 - accuracy: 0.7083\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 19s 962ms/step - loss: 0.4657 - accuracy: 0.7612\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 19s 931ms/step - loss: 0.3926 - accuracy: 0.8301\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 19s 956ms/step - loss: 0.3215 - accuracy: 0.8606\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 19s 918ms/step - loss: 0.3194 - accuracy: 0.8622\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 19s 942ms/step - loss: 0.3147 - accuracy: 0.8814\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 19s 961ms/step - loss: 0.2846 - accuracy: 0.8846\n",
            "Found 5239 images belonging to 2 classes.\n",
            "164/164 [==============================] - 188s 1s/step - loss: 0.3139 - accuracy: 0.8673\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.31388184428215027, 0.8673411011695862]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "\n",
        "data = keras.preprocessing.image.ImageDataGenerator(\n",
        "preprocessing_function=lambda x:x/255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/test\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "# Initialize empty lists to store the images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over the batches in the data generator\n",
        "for batch in data:\n",
        "    batch_images, batch_labels = batch\n",
        "    \n",
        "    # Add the batch images and labels to the respective lists\n",
        "    images.extend(batch_images)\n",
        "    labels.extend(batch_labels)\n",
        "    \n",
        "    # Break the loop when all batches have been processed\n",
        "    if len(images) >= len(data.filenames):\n",
        "        break\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# for d in data:\n",
        "#   images.append(d[0])\n",
        "#   labels.append(d[1])\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input((1600,1200,1)),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(2,2), activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(2,2), activation='relu'),\n",
        "    keras.layers.Conv2D(16,(7,7),strides=(3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Conv2D(32,(9,9),strides=(2,2), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32,activation=\"relu\"),\n",
        "    keras.layers.Dense(2,activation=\"softmax\"),\n",
        "    \n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01,nesterov=True,momentum=0.9),loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "             metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(data,verbose=1,epochs=10)\n",
        "\n",
        "data_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "preprocessing_function=lambda x:x/255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/train\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "model.evaluate(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzBi9P_HpwjZ",
        "outputId": "c34dfd79-d543-47ba-b18c-935ff0f3a749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 532, 399, 8)       208       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 264, 198, 8)       1608      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 264, 198, 8)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 130, 97, 8)        1608      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 42, 31, 16)        6288      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 21, 15, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 4, 32)          41504     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 3, 2, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                6176      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,458\n",
            "Trainable params: 57,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - 34s 1s/step - loss: 0.6778 - accuracy: 0.6250\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 20s 968ms/step - loss: 0.6629 - accuracy: 0.6250\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 19s 942ms/step - loss: 0.6615 - accuracy: 0.6250\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 19s 936ms/step - loss: 0.6610 - accuracy: 0.6250\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.6522 - accuracy: 0.6250\n",
            "Epoch 6/20\n",
            "13/20 [==================>...........] - ETA: 6s - loss: 0.6655 - accuracy: 0.6675"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "\n",
        "data = keras.preprocessing.image.ImageDataGenerator(\n",
        "preprocessing_function=lambda x:x/255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/test\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "# Initialize empty lists to store the images and labels\n",
        "# images = []\n",
        "# labels = []\n",
        "\n",
        "# # Iterate over the batches in the data generator\n",
        "# for batch in data:\n",
        "#     batch_images, batch_labels = batch\n",
        "    \n",
        "#     # Add the batch images and labels to the respective lists\n",
        "#     images.extend(batch_images)\n",
        "#     labels.extend(batch_labels)\n",
        "    \n",
        "#     # Break the loop when all batches have been processed\n",
        "#     if len(images) >= len(data.filenames):\n",
        "#         break\n",
        "\n",
        "# # Convert the lists to numpy arrays\n",
        "# images = np.array(images)\n",
        "# labels = np.array(labels)\n",
        "\n",
        "# for d in data:\n",
        "#   images.append(d[0])\n",
        "#   labels.append(d[1])\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input((1600,1200,1)),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(2,2), activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(2,2), activation='relu'),\n",
        "    keras.layers.Conv2D(16,(7,7),strides=(3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Conv2D(32,(9,9),strides=(2,2), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32,activation=\"relu\"),\n",
        "    keras.layers.Dense(2,activation=\"softmax\"),\n",
        "    \n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01,nesterov=True,momentum=0.9),loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "             metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(data,verbose=1,epochs=20)\n",
        "\n",
        "data_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "preprocessing_function=lambda x:x/255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/train\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "model.evaluate(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLhq72P9BtSD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "\n",
        "data = keras.preprocessing.image.ImageDataGenerator(\n",
        "preprocessing_function=lambda x:x/255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/test\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "# Initialize empty lists to store the images and labels\n",
        "# images = []\n",
        "# labels = []\n",
        "\n",
        "# # Iterate over the batches in the data generator\n",
        "# for batch in data:\n",
        "#     batch_images, batch_labels = batch\n",
        "    \n",
        "#     # Add the batch images and labels to the respective lists\n",
        "#     images.extend(batch_images)\n",
        "#     labels.extend(batch_labels)\n",
        "    \n",
        "#     # Break the loop when all batches have been processed\n",
        "#     if len(images) >= len(data.filenames):\n",
        "#         break\n",
        "\n",
        "# # Convert the lists to numpy arrays\n",
        "# images = np.array(images)\n",
        "# labels = np.array(labels)\n",
        "\n",
        "# # for d in data:\n",
        "# #   images.append(d[0])\n",
        "# #   labels.append(d[1])\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input((1600,1200,1)),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(2,2), activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(2,2), activation='relu'),\n",
        "    keras.layers.Conv2D(16,(7,7),strides=(3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Conv2D(32,(9,9),strides=(2,2), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32,activation=\"relu\"),\n",
        "    keras.layers.Dense(2,activation=\"softmax\"),\n",
        "    \n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01,nesterov=True,momentum=0.9),loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "             metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(data,verbose=1,epochs=20)\n",
        "\n",
        "data_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "preprocessing_function=lambda x:x/255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/train\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "model.evaluate(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoW6laOlPUQ-",
        "outputId": "300e975a-2223-4aa4-996d-a5af903b3d27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import numpy as np\n",
        "\n",
        "data = keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=lambda x: x / 255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/test\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "# Initialize empty lists to store the images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over the batches in the data generator\n",
        "for batch in data:\n",
        "    batch_images, batch_labels = batch\n",
        "\n",
        "    # Add the batch images and labels to the respective lists\n",
        "    images.extend(batch_images)\n",
        "    labels.extend(batch_labels)\n",
        "\n",
        "    # Perform undersampling on smaller batches using RandomUnderSampler\n",
        "    if len(images) >= 1024:  # Change the value according to available memory\n",
        "        # Convert the lists to numpy arrays\n",
        "        images = np.array(images)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        # Reshape the images array to 2D\n",
        "        images_reshaped = images.reshape(images.shape[0], -1)\n",
        "\n",
        "        # Perform undersampling using RandomUnderSampler\n",
        "        rus = RandomUnderSampler()\n",
        "        images_undersampled, labels_undersampled = rus.fit_resample(images_reshaped, labels)\n",
        "\n",
        "        # Reshape the images_undersampled array back to 4D\n",
        "        images_undersampled = images_undersampled.reshape(images_undersampled.shape[0], 1600, 1200, 1)\n",
        "\n",
        "        # Train the model with the undersampled data\n",
        "        model.fit(images_undersampled, labels_undersampled, verbose=1, epochs=4)\n",
        "\n",
        "        # Clear the lists for the next batch\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "# Convert the remaining images and labels to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Reshape the remaining images array to 2D\n",
        "images_reshaped = images.reshape(images.shape[0], -1)\n",
        "\n",
        "# Perform undersampling on the remaining data using RandomUnderSampler\n",
        "rus = RandomUnderSampler()\n",
        "images_undersampled, labels_undersampled = rus.fit_resample(images_reshaped, labels)\n",
        "\n",
        "# Reshape the images_undersampled array back to 4D\n",
        "images_undersampled = images_undersampled.reshape(images_undersampled.shape[0], 1600, 1200, 1)\n",
        "\n",
        "# Train the model with the undersampled data\n",
        "model.fit(images_undersampled, labels_undersampled, verbose=1, epochs=4)\n",
        "\n",
        "# Continue with the rest of the code...\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input((1600, 1200, 1)),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(3, 3), activation='relu'),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.Conv2D(16, (7, 7), strides=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Conv2D(32, (9, 9), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(2, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01, nesterov=True, momentum=0.9),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(images_undersampled, labels_undersampled, verbose=1, epochs=4)\n",
        "\n",
        "\n",
        "data_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=lambda x: x / 255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/train\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "model.evaluate(data_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LHISojBFDWV",
        "outputId": "47f7e912-0fe3-44f7-a8fa-cd799c50d5bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 532, 399, 8)       208       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 264, 198, 8)       1608      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 264, 198, 8)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 130, 97, 8)        1608      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 42, 31, 16)        6288      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 21, 15, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 4, 32)          41504     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 3, 2, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                6176      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,458\n",
            "Trainable params: 57,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/4\n",
            "20/20 [==============================] - 30s 797ms/step - loss: 0.6930 - accuracy: 0.3974\n",
            "Epoch 2/4\n",
            "20/20 [==============================] - 18s 908ms/step - loss: 0.6911 - accuracy: 0.6362\n",
            "Epoch 3/4\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.6725 - accuracy: 0.5865\n",
            "Epoch 4/4\n",
            "20/20 [==============================] - 19s 925ms/step - loss: 0.6700 - accuracy: 0.5689\n",
            "Found 5239 images belonging to 2 classes.\n",
            "164/164 [==============================] - 2888s 18s/step - loss: 0.6464 - accuracy: 0.7412\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6463626623153687, 0.7411719560623169]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "data = keras.preprocessing.image.ImageDataGenerator(\n",
        "preprocessing_function=lambda x:x/255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/test\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = np.array([1.3333, 0.8])\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input((1600, 1200, 1)),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(3, 3), activation='relu'),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.Conv2D(16, (7, 7), strides=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Conv2D(32, (9, 9), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(2, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.01, nesterov=True, momentum=0.9),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(data, verbose=1, epochs=4, class_weight=dict(enumerate(class_weights)))\n",
        "\n",
        "data_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=lambda x: x / 255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/train\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "model.evaluate(data_test)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYw-bm83GTx3",
        "outputId": "1fcf01aa-f763-40be-97ee-3dcf83662c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(type(class_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyAVQsJjBvtv",
        "outputId": "f42285ec-7822-4d09-db21-afd37610c36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 532, 399, 8)       208       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 264, 198, 8)       1608      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 264, 198, 8)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 130, 97, 8)        1608      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 42, 31, 16)        6288      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 21, 15, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 4, 32)          41504     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 3, 2, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                6176      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,458\n",
            "Trainable params: 57,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/4\n",
            "20/20 [==============================] - 23s 803ms/step - loss: 0.6892 - accuracy: 0.5865\n",
            "Epoch 2/4\n",
            "20/20 [==============================] - 18s 915ms/step - loss: 0.6661 - accuracy: 0.6442\n",
            "Epoch 3/4\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.7981 - accuracy: 0.7099\n",
            "Epoch 4/4\n",
            "20/20 [==============================] - 18s 905ms/step - loss: 0.6950 - accuracy: 0.6250\n",
            "Found 5239 images belonging to 2 classes.\n",
            "164/164 [==============================] - 173s 1s/step - loss: 0.6808 - accuracy: 0.7412\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.680750846862793, 0.7411719560623169]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "data = keras.preprocessing.image.ImageDataGenerator(\n",
        "preprocessing_function=lambda x:x/255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/test\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = np.array([1.3333, 0.8])\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input((1600, 1200, 1)),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(3, 3), activation='relu'),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.Conv2D(16, (7, 7), strides=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Conv2D(32, (9, 9), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(2, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.01, nesterov=True, momentum=0.9),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(data, verbose=1, epochs=4, class_weight=dict(enumerate(class_weights)))\n",
        "\n",
        "data_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=lambda x: x / 255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/train\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "model.evaluate(data_test)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NDTXqITZuy6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXm_SM8_Zvgo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-U1BQrnSX2l",
        "outputId": "6be87017-c5af-4135-f817-15bedddea4d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.33333333 0.8       ]\n"
          ]
        }
      ],
      "source": [
        "class_weights = class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(np.argmax(labels, axis=1)), y = np.argmax(labels, axis=1))\n",
        "\n",
        "print(class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8HliW9YZwND",
        "outputId": "eaac455f-673e-4b46-899f-e4da38ce215c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 532, 399, 8)       208       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 264, 198, 8)       1608      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 264, 198, 8)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 130, 97, 8)        1608      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 42, 31, 16)        6288      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 21, 15, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 4, 32)          41504     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 3, 2, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                6176      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,458\n",
            "Trainable params: 57,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 101s 5s/step - loss: 0.6931 - accuracy: 0.4856\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.6848 - accuracy: 0.5016\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 98s 5s/step - loss: 0.6678 - accuracy: 0.5994\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.6510 - accuracy: 0.6266\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.6959 - accuracy: 0.6250\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.6944 - accuracy: 0.5353\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.6935 - accuracy: 0.3686\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.6934 - accuracy: 0.5192\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.6936 - accuracy: 0.4519\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.6938 - accuracy: 0.5545\n",
            "Found 5239 images belonging to 2 classes.\n",
            "164/164 [==============================] - 169s 1s/step - loss: 0.6896 - accuracy: 0.7412\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6895645260810852, 0.7411719560623169]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "data = keras.preprocessing.image.ImageDataGenerator(\n",
        "preprocessing_function=lambda x: x / 255,\n",
        "    rotation_range=20,  # Random rotation in the range of [-20, 20] degrees\n",
        "    width_shift_range=0.2,  # Random horizontal shift by 20% of the image width\n",
        "    height_shift_range=0.2,  # Random vertical shift by 20% of the image height\n",
        "    shear_range=0.2,  # Shear transformation with a range of 0.2\n",
        "    zoom_range=0.2,  # Random zoom in/out by 20%\n",
        "    horizontal_flip=True  # \n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/test\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = np.array([1.3333, 0.8])\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input((1600, 1200, 1)),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(3, 3), activation='relu'),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.Conv2D(16, (7, 7), strides=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Conv2D(32, (9, 9), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(2, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.01, nesterov=True, momentum=0.9),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(data, verbose=1, epochs=10, class_weight=dict(enumerate(class_weights)))\n",
        "\n",
        "data_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=lambda x: x / 255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/train\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "model.evaluate(data_test)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_JQTGUmlZ5Q",
        "outputId": "a99ecc5b-1c65-4acb-fc79-950c47b477de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "\n",
        "train_data = keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=lambda x: x / 255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/test\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "# Extract the features and labels from the training data\n",
        "train_features, train_labels = next(train_data)\n",
        "\n",
        "# Reshape the train_features array to 2D\n",
        "train_features_2d = np.reshape(train_features, (train_features.shape[0], -1))\n",
        "\n",
        "# Calculate the number of samples in the minority class\n",
        "num_minority_samples = np.sum(train_labels[:, 1])\n",
        "\n",
        "# Determine the number of neighbors for SMOTE\n",
        "k_neighbors = min(6, num_minority_samples - 1)\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(k_neighbors=k_neighbors)\n",
        "train_features_resampled, train_labels_resampled = smote.fit_resample(train_features_2d, train_labels)\n",
        "\n",
        "# Reshape the train_features_resampled array back to 4D\n",
        "train_features_resampled = np.reshape(train_features_resampled, (train_features_resampled.shape[0], 1600, 1200, 1))\n",
        "\n",
        "# Create a new data generator using the resampled data\n",
        "resampled_train_data = tf.data.Dataset.from_tensor_slices((train_features_resampled, train_labels_resampled))\n",
        "resampled_train_data = resampled_train_data.batch(32).prefetch(1)\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input((1600,1200,1)),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(2,2), activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Conv2D(8,(5,5),strides=(2,2), activation='relu'),\n",
        "    keras.layers.Conv2D(16,(7,7),strides=(3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Conv2D(32,(9,9),strides=(2,2), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32,activation=\"relu\"),\n",
        "    keras.layers.Dense(2,activation=\"softmax\"),\n",
        "    \n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01,nesterov=True,momentum=0.9),loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "             metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(resampled_train_data, verbose=1, epochs=4)\n",
        "\n",
        "\n",
        "data_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=lambda x: x/255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/train\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "model.evaluate(data_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFg313N1j5jW"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# import numpy as np\n",
        "\n",
        "# # Define the input shape\n",
        "# input_shape = (1600, 1200, 1)\n",
        "\n",
        "# # Get the number of samples per class in the training data\n",
        "# train_data = keras.preprocessing.image.ImageDataGenerator().flow_from_directory(\n",
        "#     \"/content/gdrive/MyDrive/chest/datai2/chest_xray/train\",\n",
        "#     target_size=input_shape[:2],\n",
        "#     color_mode='grayscale',\n",
        "#     classes=None,\n",
        "#     class_mode='categorical',\n",
        "#     batch_size=32,\n",
        "#     shuffle=False\n",
        "# )\n",
        "\n",
        "# class_labels = train_data.classes\n",
        "# class_counts = np.bincount(class_labels)\n",
        "# total_samples = np.sum(class_counts)\n",
        "# class_weights = {i: total_samples / count for i, count in enumerate(class_counts)}\n",
        "\n",
        "# # Define the model\n",
        "# model = keras.Sequential([\n",
        "#     keras.layers.Input(input_shape),\n",
        "#     keras.layers.Conv2D(8, (5, 5), strides=(3, 3), activation='relu'),\n",
        "#     keras.layers.Conv2D(8, (5, 5), strides=(2, 2), activation='relu'),\n",
        "#     keras.layers.Dropout(0.1),\n",
        "#     keras.layers.Conv2D(8, (5, 5), strides=(2, 2), activation='relu'),\n",
        "#     keras.layers.Conv2D(16, (7, 7), strides=(3, 3), activation='relu'),\n",
        "#     keras.layers.MaxPool2D((2, 2)),\n",
        "#     keras.layers.Conv2D(32, (9, 9), strides=(2, 2), activation='relu'),\n",
        "#     keras.layers.MaxPool2D((2, 2)),\n",
        "#     keras.layers.Flatten(),\n",
        "#     keras.layers.Dense(32, activation=\"relu\"),\n",
        "#     keras.layers.Dense(2, activation=\"softmax\")\n",
        "# ])\n",
        "\n",
        "# # Compile the model with class weights\n",
        "# model.compile(\n",
        "#     optimizer=keras.optimizers.SGD(learning_rate=0.01, nesterov=True, momentum=0.9),\n",
        "#     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#     metrics=[\"accuracy\"],\n",
        "#     weighted_metrics=[\"accuracy\"]\n",
        "# )\n",
        "\n",
        "# # Train the model with class weights\n",
        "# history = model.fit(\n",
        "#     train_data,\n",
        "#     verbose=1,\n",
        "#     epochs=4,\n",
        "#     class_weight=class_weights\n",
        "# )\n",
        "\n",
        "# # Evaluate the model on test data\n",
        "# data_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "#     preprocessing_function=lambda x: x/255\n",
        "# ).flow_from_directory(\n",
        "#     \"/content/gdrive/MyDrive/chest/datai2/chest_xray/test\",\n",
        "#     target_size=input_shape[:2],\n",
        "#     color_mode='grayscale',\n",
        "#     classes=None,\n",
        "#     class_mode='categorical',\n",
        "#     batch_size=32,\n",
        "#     shuffle=False\n",
        "# )\n",
        "\n",
        "# model.evaluate(data_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "kloBw_f0lI2p",
        "outputId": "41905ecf-4667-4489-ac88-982e48365fb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e08b9e83e9be>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7261\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7262\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__ConcatV2_N_20_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[624,1600,1200,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ConcatV2] name: concat"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "\n",
        "data = keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=lambda x: x / 255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/test\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "# Extract the features (images) and labels from the data generator\n",
        "features = []\n",
        "labels = []\n",
        "for batch_features, batch_labels in data:\n",
        "    features.append(batch_features)\n",
        "    labels.append(batch_labels)\n",
        "    if len(features) * data.batch_size >= len(data.filenames):\n",
        "        break\n",
        "\n",
        "features = tf.concat(features, axis=0)\n",
        "labels = tf.concat(labels, axis=0)\n",
        "\n",
        "# Convert TensorFlow eager tensors to NumPy arrays\n",
        "features = features.numpy()\n",
        "labels = labels.numpy()\n",
        "\n",
        "# Reshape the features to match the requirements of RandomOverSampler\n",
        "features = features.reshape(features.shape[0], -1)\n",
        "\n",
        "# Apply RandomOverSampler to oversample the data\n",
        "oversampler = RandomOverSampler(sampling_strategy=0.5)\n",
        "oversampled_features, oversampled_labels = oversampler.fit_resample(features, labels)\n",
        "\n",
        "# Reshape the oversampled features back to the original shape\n",
        "oversampled_features = oversampled_features.reshape(\n",
        "    oversampled_features.shape[0], 1600, 1200, 1\n",
        ")\n",
        "\n",
        "# Convert the oversampled features and labels back to TensorFlow tensors\n",
        "oversampled_features = tf.convert_to_tensor(oversampled_features)\n",
        "oversampled_labels = tf.convert_to_tensor(oversampled_labels)\n",
        "\n",
        "# Create a TensorFlow Dataset from the oversampled features and labels\n",
        "oversampled_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (oversampled_features, oversampled_labels)\n",
        ")\n",
        "oversampled_data = oversampled_data.batch(data.batch_size)\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input((1600,1200,1)),\n",
        "    keras.layers.Conv2D(8, (5,5), strides=(3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(8, (5,5), strides=(2,2), activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Conv2D(8, (5,5), strides=(2,2), activation='relu'),\n",
        "    keras.layers.Conv2D(16, (7,7), strides=(3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Conv2D(32, (9,9), strides=(2,2), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(2, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.01, nesterov=True, momentum=0.9),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(oversampled_data, verbose=1, epochs=4)\n",
        "\n",
        "data_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=lambda x: x/255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/train\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "model.evaluate(data_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdJCfWPXKwF2",
        "outputId": "f071858c-15f7-4eba-e94e-67110be84363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "\n",
        "data = keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=lambda x: x / 255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/test\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "# Initialize empty lists to store features and labels\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over the data generator and process in smaller batches\n",
        "for i in range(len(data)):\n",
        "    batch_features, batch_labels = data[i]\n",
        "    \n",
        "   \n",
        "    \n",
        "    # Reshape the features to match the requirements of RandomOverSampler\n",
        "    batch_features = batch_features.reshape(batch_features.shape[0], -1)\n",
        "    \n",
        "    # Append the features and labels to the lists\n",
        "    features.append(batch_features)\n",
        "    labels.append(batch_labels)\n",
        "\n",
        "# Concatenate the features and labels\n",
        "features = np.concatenate(features, axis=0)\n",
        "labels = np.concatenate(labels, axis=0)\n",
        "\n",
        "# Apply RandomOverSampler to oversample the data\n",
        "oversampler = RandomOverSampler(sampling_strategy='auto')\n",
        "oversampled_features, oversampled_labels = oversampler.fit_resample(features, labels)\n",
        "\n",
        "# Reshape the oversampled features back to the original shape\n",
        "oversampled_features = oversampled_features.reshape(\n",
        "    oversampled_features.shape[0], 1600, 1200, 1\n",
        ")\n",
        "\n",
        "# Convert the oversampled features and labels to TensorFlow tensors\n",
        "oversampled_features = tf.convert_to_tensor(oversampled_features)\n",
        "oversampled_labels = tf.convert_to_tensor(oversampled_labels)\n",
        "\n",
        "# Create a TensorFlow Dataset from the oversampled features and labels\n",
        "oversampled_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (oversampled_features, oversampled_labels)\n",
        ")\n",
        "oversampled_data = oversampled_data.batch(data.batch_size)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input((1600, 1200, 1)),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(3, 3), activation='relu'),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Conv2D(8, (5, 5), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.Conv2D(16, (7, 7), strides=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Conv2D(32, (9, 9), strides=(2, 2), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(2, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=0.01, nesterov=True, momentum=0.9),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(oversampled_data, verbose=1, epochs=4)\n",
        "\n",
        "data_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=lambda x: x / 255\n",
        ").flow_from_directory(\n",
        "    \"/content/gdrive/MyDrive/chest/datai2/chest_xray/train\",\n",
        "    target_size=(1600, 1200),\n",
        "    color_mode='grayscale',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    save_to_dir=None,\n",
        "    save_prefix='',\n",
        "    save_format='png',\n",
        "    follow_links=False,\n",
        "    subset=None,\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "\n",
        "model.evaluate(data_test)\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u56urDMVMbOM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}